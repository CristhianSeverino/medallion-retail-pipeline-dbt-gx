{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMBo/GnTfL73ys04lzFiB54",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "da9442185a944641a2315e8dbfe8af74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_502ba005710b4413808d025d05bb6519",
              "IPY_MODEL_6c3c8962073a4a82900f7e1c6cd14ef2",
              "IPY_MODEL_89eae199bdff41e48ea624f461457967"
            ],
            "layout": "IPY_MODEL_e07a1fde00ba42b3a72a88911053d10f"
          }
        },
        "502ba005710b4413808d025d05bb6519": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6f8cc529591484996f483c4fa819cc9",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_6dd4f37430454e3c8d68df8f98600af0",
            "value": "Calculatingâ€‡Metrics:â€‡100%"
          }
        },
        "6c3c8962073a4a82900f7e1c6cd14ef2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f4034c147ff480c91f9900ab58822ee",
            "max": 49,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d5253076ab144daea5cf3f07a026b5f5",
            "value": 49
          }
        },
        "89eae199bdff41e48ea624f461457967": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcac71ee2393441ab33e5268b3df5d25",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1ae89111cd5348a88dcbb984e9a3d10a",
            "value": "â€‡49/49â€‡[00:00&lt;00:00,â€‡631.78it/s]"
          }
        },
        "e07a1fde00ba42b3a72a88911053d10f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6f8cc529591484996f483c4fa819cc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6dd4f37430454e3c8d68df8f98600af0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f4034c147ff480c91f9900ab58822ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5253076ab144daea5cf3f07a026b5f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bcac71ee2393441ab33e5268b3df5d25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ae89111cd5348a88dcbb984e9a3d10a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CristhianSeverino/medallion-retail-pipeline-dbt-gx/blob/main/dbt_Exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **dbt + Great Expectations Practice â€“ Modern Data Pipeline Demo**\n",
        "\n",
        "> Created by **Cristhian Calle Severino**  \n",
        "> Senior Solution Architect | BI Lead | Data Strategist\n",
        "\n",
        ">>Demonstrating Medallion Architecture, Kimball modeling, automated testing, and proactive data governance with Great Expectations.\n",
        "\n",
        "\n",
        "\n",
        "**If you find this notebook useful, I'd love to hear your thoughts!**  \n",
        "**Have fun exploring!** ğŸ˜Š\n",
        "\n",
        "\n",
        "\n",
        "- **GitHub**: https://github.com/CristhianSeverino  \n",
        "- **LinkedIn**: https://www.linkedin.com/in/cristhianandrescalleseverino/  \n",
        "- **Portfolio**: https://sites.google.com/view/cristhiancalle  \n"
      ],
      "metadata": {
        "id": "binHEwRk-msI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Install Libraries & Dependencies ğŸ“¦\n",
        "\n",
        "> Installs required packages (dbt-core, dbt-duckdb, pandas, Great Expectations).\n",
        "\n",
        "> **Note**: If Colab prompts for a runtime restart after installation, please do so before continuing. This is common when upgrading core libraries. ğŸš¨"
      ],
      "metadata": {
        "id": "tiS3J4l5-Y_-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wFSIYue_Jxv9",
        "outputId": "4b22aba2-5992-45b0-9d9b-f95093544180"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dbt-core\n",
            "  Downloading dbt_core-1.11.2-py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting dbt-duckdb\n",
            "  Downloading dbt_duckdb-1.10.0-py3-none-any.whl.metadata (36 kB)\n",
            "Collecting great-expectations\n",
            "  Downloading great_expectations-1.11.0-py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting agate<1.10,>=1.7.0 (from dbt-core)\n",
            "  Downloading agate-1.9.1-py2.py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: click<9.0,>=8.2.0 in /usr/local/lib/python3.12/dist-packages (from dbt-core) (8.3.1)\n",
            "Collecting daff>=1.3.46 (from dbt-core)\n",
            "  Downloading daff-1.4.2-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting dbt-adapters<2.0,>=1.15.5 (from dbt-core)\n",
            "  Downloading dbt_adapters-1.22.5-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting dbt-common<2.0,>=1.37.2 (from dbt-core)\n",
            "  Downloading dbt_common-1.37.2-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting dbt-extractor<=0.6,>=0.5.0 (from dbt-core)\n",
            "  Downloading dbt_extractor-0.6.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
            "Collecting dbt-protos<2.0,>=1.0.405 (from dbt-core)\n",
            "  Downloading dbt_protos-1.0.419-py3-none-any.whl.metadata (859 bytes)\n",
            "Collecting dbt-semantic-interfaces<0.10,>=0.9.0 (from dbt-core)\n",
            "  Downloading dbt_semantic_interfaces-0.9.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: jinja2<4,>=3.1.3 in /usr/local/lib/python3.12/dist-packages (from dbt-core) (3.1.6)\n",
            "Requirement already satisfied: jsonschema<5.0,>=4.19.1 in /usr/local/lib/python3.12/dist-packages (from dbt-core) (4.26.0)\n",
            "Collecting mashumaro<3.15,>=3.9 (from mashumaro[msgpack]<3.15,>=3.9->dbt-core)\n",
            "  Downloading mashumaro-3.14-py3-none-any.whl.metadata (114 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m114.4/114.4 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: networkx<4.0,>=2.3 in /usr/local/lib/python3.12/dist-packages (from dbt-core) (3.6.1)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.12/dist-packages (from dbt-core) (25.0)\n",
            "Collecting pathspec<0.13,>=0.9 (from dbt-core)\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting protobuf<7.0,>=6.0 (from dbt-core)\n",
            "  Downloading protobuf-6.33.4-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from dbt-core) (2.12.3)\n",
            "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.12/dist-packages (from dbt-core) (2025.2)\n",
            "Requirement already satisfied: pyyaml>=6.0 in /usr/local/lib/python3.12/dist-packages (from dbt-core) (6.0.3)\n",
            "Requirement already satisfied: requests<3.0.0 in /usr/local/lib/python3.12/dist-packages (from dbt-core) (2.32.4)\n",
            "Collecting snowplow-tracker<2.0,>=1.0.2 (from dbt-core)\n",
            "  Downloading snowplow_tracker-1.1.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting sqlparse<0.5.5,>=0.5.0 (from dbt-core)\n",
            "  Downloading sqlparse-0.5.4-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.4 in /usr/local/lib/python3.12/dist-packages (from dbt-core) (4.15.0)\n",
            "Requirement already satisfied: duckdb>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from dbt-duckdb) (1.3.2)\n",
            "Collecting altair<5.0.0,>=4.2.1 (from great-expectations)\n",
            "  Downloading altair-4.2.2-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: cryptography>=3.2 in /usr/local/lib/python3.12/dist-packages (from great-expectations) (43.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.7.1 (from great-expectations)\n",
            "  Downloading marshmallow-3.26.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: mistune>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from great-expectations) (3.2.0)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.12/dist-packages (from great-expectations) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from great-expectations) (2.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.2.4,>=2.4 in /usr/local/lib/python3.12/dist-packages (from great-expectations) (3.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.12/dist-packages (from great-expectations) (2.9.0.post0)\n",
            "Collecting ruamel.yaml>=0.16 (from great-expectations)\n",
            "  Downloading ruamel_yaml-0.19.1-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from great-expectations) (1.16.3)\n",
            "Requirement already satisfied: tqdm>=4.59.0 in /usr/local/lib/python3.12/dist-packages (from great-expectations) (4.67.1)\n",
            "Requirement already satisfied: tzlocal>=1.2 in /usr/local/lib/python3.12/dist-packages (from great-expectations) (5.3.1)\n",
            "Requirement already satisfied: Babel>=2.0 in /usr/local/lib/python3.12/dist-packages (from agate<1.10,>=1.7.0->dbt-core) (2.17.0)\n",
            "Collecting isodate>=0.5.4 (from agate<1.10,>=1.7.0->dbt-core)\n",
            "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting leather>=0.3.2 (from agate<1.10,>=1.7.0->dbt-core)\n",
            "  Downloading leather-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting parsedatetime!=2.5,>=2.1 (from agate<1.10,>=1.7.0->dbt-core)\n",
            "  Downloading parsedatetime-2.6-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: python-slugify>=1.2.1 in /usr/local/lib/python3.12/dist-packages (from agate<1.10,>=1.7.0->dbt-core) (8.0.4)\n",
            "Collecting pytimeparse>=1.1.5 (from agate<1.10,>=1.7.0->dbt-core)\n",
            "  Downloading pytimeparse-1.1.8-py2.py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from altair<5.0.0,>=4.2.1->great-expectations) (0.4)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.12/dist-packages (from altair<5.0.0,>=4.2.1->great-expectations) (0.12.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=3.2->great-expectations) (2.0.0)\n",
            "Collecting colorama<0.5,>=0.3.9 (from dbt-common<2.0,>=1.37.2->dbt-core)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting deepdiff<9.0,>=7.0 (from dbt-common<2.0,>=1.37.2->dbt-core)\n",
            "  Downloading deepdiff-8.6.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: importlib-metadata<9,>=6.0 in /usr/local/lib/python3.12/dist-packages (from dbt-semantic-interfaces<0.10,>=0.9.0->dbt-core) (8.7.1)\n",
            "Requirement already satisfied: more-itertools<11.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from dbt-semantic-interfaces<0.10,>=0.9.0->dbt-core) (10.8.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2<4,>=3.1.3->dbt-core) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0,>=4.19.1->dbt-core) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0,>=4.19.1->dbt-core) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0,>=4.19.1->dbt-core) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0,>=4.19.1->dbt-core) (0.30.0)\n",
            "Requirement already satisfied: msgpack>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from mashumaro[msgpack]<3.15,>=3.9->dbt-core) (1.1.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.0->great-expectations) (2025.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->dbt-core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->dbt-core) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->dbt-core) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.1->great-expectations) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0->dbt-core) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0->dbt-core) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0->dbt-core) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0->dbt-core) (2026.1.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=3.2->great-expectations) (2.23)\n",
            "Collecting orderly-set<6,>=5.4.1 (from deepdiff<9.0,>=7.0->dbt-common<2.0,>=1.37.2->dbt-core)\n",
            "  Downloading orderly_set-5.5.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<9,>=6.0->dbt-semantic-interfaces<0.10,>=0.9.0->dbt-core) (3.23.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.12/dist-packages (from python-slugify>=1.2.1->agate<1.10,>=1.7.0->dbt-core) (1.3)\n",
            "Downloading dbt_core-1.11.2-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dbt_duckdb-1.10.0-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m82.9/82.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading great_expectations-1.11.0-py3-none-any.whl (4.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading agate-1.9.1-py2.py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m95.1/95.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading altair-4.2.2-py3-none-any.whl (813 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m813.6/813.6 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading daff-1.4.2-py3-none-any.whl (144 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m144.9/144.9 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dbt_adapters-1.22.5-py3-none-any.whl (172 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m172.8/172.8 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dbt_common-1.37.2-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m87.7/87.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dbt_extractor-0.6.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m442.7/442.7 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dbt_protos-1.0.419-py3-none-any.whl (167 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m167.1/167.1 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dbt_semantic_interfaces-0.9.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m147.0/147.0 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.2-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mashumaro-3.14-py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m92.2/92.2 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Downloading protobuf-6.33.4-cp39-abi3-manylinux2014_x86_64.whl (323 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m323.3/323.3 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruamel_yaml-0.19.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m118.1/118.1 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading snowplow_tracker-1.1.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sqlparse-0.5.4-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45.9/45.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading deepdiff-8.6.1-py3-none-any.whl (91 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m91.4/91.4 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
            "Downloading leather-0.4.1-py3-none-any.whl (30 kB)\n",
            "Downloading parsedatetime-2.6-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytimeparse-1.1.8-py2.py3-none-any.whl (10.0 kB)\n",
            "Downloading orderly_set-5.5.0-py3-none-any.whl (13 kB)\n",
            "Installing collected packages: pytimeparse, parsedatetime, leather, daff, sqlparse, ruamel.yaml, protobuf, pathspec, orderly-set, mashumaro, marshmallow, isodate, dbt-extractor, colorama, snowplow-tracker, deepdiff, dbt-protos, agate, dbt-semantic-interfaces, dbt-common, altair, great-expectations, dbt-adapters, dbt-core, dbt-duckdb\n",
            "  Attempting uninstall: sqlparse\n",
            "    Found existing installation: sqlparse 0.5.5\n",
            "    Uninstalling sqlparse-0.5.5:\n",
            "      Successfully uninstalled sqlparse-0.5.5\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "  Attempting uninstall: altair\n",
            "    Found existing installation: altair 5.5.0\n",
            "    Uninstalling altair-5.5.0:\n",
            "      Successfully uninstalled altair-5.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 6.33.4 which is incompatible.\n",
            "tensorflow 2.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.4 which is incompatible.\n",
            "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.33.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed agate-1.9.1 altair-4.2.2 colorama-0.4.6 daff-1.4.2 dbt-adapters-1.22.5 dbt-common-1.37.2 dbt-core-1.11.2 dbt-duckdb-1.10.0 dbt-extractor-0.6.0 dbt-protos-1.0.419 dbt-semantic-interfaces-0.9.0 deepdiff-8.6.1 great-expectations-1.11.0 isodate-0.7.2 leather-0.4.1 marshmallow-3.26.2 mashumaro-3.14 orderly-set-5.5.0 parsedatetime-2.6 pathspec-0.12.1 protobuf-6.33.4 pytimeparse-1.1.8 ruamel.yaml-0.19.1 snowplow-tracker-1.1.0 sqlparse-0.5.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "cfbd59259b494d419e83585e71aeeec3"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Celda 1: Instalall (dbt, GX, pandas, duckdb)\n",
        "!pip install --upgrade dbt-core dbt-duckdb great-expectations"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. **Import Libraries ğŸ“š**\n"
      ],
      "metadata": {
        "id": "CLzptNVY-ycW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import duckdb\n",
        "import great_expectations as gx\n",
        "import json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moN3f0mgAiKP",
        "outputId": "daf40dae-045d-4be7-f61c-5d8dd9970aa2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Synthetic Data Generation â€“ Simulated ERP Dataset ğŸ› ï¸\n",
        "\n",
        "> In this section, we generate a synthetic ERP dataset to emulate real-world data challenges.  \n",
        "\n",
        "> The simulated ERP intentionally includes **lack of proper data architecture and governance** (e.g., negative quantities, invalid keys, zero metrics, inconsistencies), allowing us to demonstrate cleaning (silver), aggregation (gold), and quality validation (GX) in the following steps.\n"
      ],
      "metadata": {
        "id": "hKRhw5ku_RMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: More complex data generation (emulating a realistic ERP with anomalies)\n",
        "# Fixed typos: import pandas, np.random.poisson, np.random.randint, anomaly_idx, np.random.choice\n",
        "\n",
        "\n",
        "np.random.seed(42)  # Reproducibilidad\n",
        "\n",
        "# dim_time:  with holidays flag and week_day\n",
        "\n",
        "dates = pd.date_range(start='2023-01-01', end='2026-01-15', freq='D')\n",
        "dim_time = pd.DataFrame({\n",
        "    'time_id': range(1, len(dates) + 1),\n",
        "    'date': dates,\n",
        "    'year': dates.year,\n",
        "    'month': dates.month,\n",
        "    'day': dates.day,\n",
        "    'quarter': dates.quarter,\n",
        "    'week_day': dates.strftime('%A'),  # DÃ­a de la semana\n",
        "    'is_holiday': np.random.choice([0, 1], len(dates), p=[0.95, 0.05])  # 5% holidays\n",
        "})\n",
        "\n",
        "# dim_location\n",
        "dim_location = pd.DataFrame({\n",
        "    'location_id': range(1, 11),\n",
        "    'region': np.random.choice(['North', 'South', 'East', 'West', 'Central'], 10),\n",
        "    'country': ['USA'] * 10,\n",
        "    'city': np.random.choice(['New York', 'Miami', 'Chicago', 'LA', 'Dallas'], 10)\n",
        "})\n",
        "\n",
        "# dim_customer: Add loyalty_level\n",
        "dim_customer = pd.DataFrame({\n",
        "    'customer_id': range(1, 501),  # more customers\n",
        "    'name': ['Customer ' + str(i) for i in range(1, 501)],\n",
        "    'segment': np.random.choice(['Consumer', 'Corporate', 'Home Office'], 500),\n",
        "    'loyalty_level': np.random.choice(['Bronze', 'Silver', 'Gold'], 500, p=[0.6, 0.3, 0.1])\n",
        "})\n",
        "\n",
        "# dim_product: add subcategory, cost\n",
        "dim_product = pd.DataFrame({\n",
        "    'product_id': range(1, 201),  # more products\n",
        "    'name': ['Product ' + str(i) for i in range(1, 201)],\n",
        "    'category': np.random.choice(['Furniture', 'Office Supplies', 'Technology'], 200),\n",
        "    'subcategory': np.random.choice(['Chairs', 'Desks', 'Phones', 'Binders'], 200),\n",
        "    'cost': np.random.uniform(5, 300, 200).round(2)  # Calculate profit later\n",
        "})\n",
        "\n",
        "# fact_sales: 10k rows, with discounts, tax, timestamps, anomalies (5% negative quantity, 2% invalid region_id, revenue mismatches)\n",
        "num_sales = 10000\n",
        "fact_sales = pd.DataFrame({\n",
        "    'sale_id': range(1, num_sales + 1),\n",
        "    'time_id': np.random.choice(dim_time['time_id'], num_sales),\n",
        "    'customer_id': np.random.choice(dim_customer['customer_id'], num_sales),\n",
        "    'product_id': np.random.choice(dim_product['product_id'], num_sales),\n",
        "    'location_id': np.random.choice(dim_location['location_id'], num_sales),\n",
        "    'quantity': np.random.poisson(3, num_sales) + 1,  # Media 3, min 1\n",
        "    'price': np.random.uniform(10, 500, num_sales).round(2),\n",
        "    'discount': np.random.uniform(0, 0.2, num_sales).round(2),  # 0-20%\n",
        "    'tax_rate': np.random.choice([0.05, 0.07, 0.1], num_sales),  # Tax variants\n",
        "    'sale_timestamp': [datetime.now() - timedelta(days=np.random.randint(0, 1095)) for _ in range(num_sales)]  # Last 3 years\n",
        "})\n",
        "\n",
        "# Calculate revenue with discount and tax\n",
        "fact_sales['revenue_before_discount'] = fact_sales['quantity'] * fact_sales['price']\n",
        "fact_sales['revenue'] = fact_sales['revenue_before_discount'] * (1 - fact_sales['discount']) * (1 + fact_sales['tax_rate'])\n",
        "\n",
        "# Add intentional anomalies for testing\n",
        "anomaly_idx = np.random.choice(num_sales, int(num_sales * 0.05), replace=False)\n",
        "fact_sales.loc[anomaly_idx, 'quantity'] = fact_sales.loc[anomaly_idx, 'quantity'] * -1  # Negatives\n",
        "fact_sales.loc[np.random.choice(num_sales, int(num_sales * 0.02)), 'location_id'] = -1  # Invalid ID\n",
        "fact_sales.loc[np.random.choice(num_sales, int(num_sales * 0.01)), 'revenue'] = 0  # Zero revenue anomalies\n",
        "\n",
        "# Export\n",
        "fact_sales.to_csv('fact_sales.csv', index=False)\n",
        "dim_customer.to_csv('dim_customer.csv', index=False)\n",
        "dim_product.to_csv('dim_product.csv', index=False)\n",
        "dim_time.to_csv('dim_time.csv', index=False)\n",
        "dim_location.to_csv('dim_location.csv', index=False)\n",
        "print(\"Datos complejos generados: \", fact_sales.shape, \" anomalÃ­as incluidas.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puF1AWkRXaB8",
        "outputId": "545f16ac-3a09-43be-e5af-ed95461eef21"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datos complejos generados:  (10000, 12)  anomalÃ­as incluidas.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. dbt + DuckDB â€“ Local ELT Engine & Medallion Architecture ğŸ§±\n",
        "\n",
        "> Here we set up **dbt with DuckDB** as our lightweight, in-memory analytical engine.  \n",
        "\n",
        "> This combination allows us to implement a full **Medallion Architecture** (Bronze â†’ Silver â†’ Gold) with dimensional modeling (Kimball) in a completely local, reproducible, and zero-cost environment â€” ideal for prototyping and demos.  \n",
        "\n",
        "**Why this matters**:  \n",
        "In production, this exact pipeline scales seamlessly to Snowflake, Redshift, or BigQuery by simply changing the adapter â€” demonstrating true **portability** and **cloud-agnostic design**, a core principle in modern data platforms."
      ],
      "metadata": {
        "id": "hqvJ27ORA6yn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Create project and manual configuration (to avoid interactive prompts)\n",
        "\n",
        "\n",
        "project_dir = '/content/sales_analytics'\n",
        "os.makedirs(project_dir, exist_ok=True)\n",
        "os.chdir(project_dir)\n",
        "\n",
        "# Create dbt_project.yml bÃ¡sico\n",
        "with open('dbt_project.yml', 'w') as f:\n",
        "    f.write(\"\"\"\n",
        "name: 'sales_analytics'\n",
        "version: '1.0.0'\n",
        "config-version: 2\n",
        "\n",
        "profile: 'sales_analytics'\n",
        "\n",
        "model-paths: [\"models\"]\n",
        "analysis-paths: [\"analyses\"]\n",
        "test-paths: [\"tests\"]\n",
        "seed-paths: [\"seeds\"]\n",
        "macro-paths: [\"macros\"]\n",
        "snapshot-paths: [\"snapshots\"]\n",
        "\n",
        "target-path: \"target\"\n",
        "clean-targets: [\"target\", \"dbt_packages\"]\n",
        "\n",
        "models:\n",
        "  sales_analytics:\n",
        "    +materialized: table\n",
        "\"\"\")\n",
        "\n",
        "# Create profiles.yml\n",
        "with open('profiles.yml', 'w') as f:\n",
        "    f.write(\"\"\"\n",
        "sales_analytics:\n",
        "  target: dev\n",
        "  outputs:\n",
        "    dev:\n",
        "      type: duckdb\n",
        "      path: /content/sales_analytics/sales.duckdb\n",
        "      threads: 4\n",
        "\"\"\")\n",
        "\n",
        "print(\"Proyecto creado manualmente.\")\n",
        "!ls -la"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9eHU2AmXexX",
        "outputId": "3f2e83f0-dd6a-42ca-b6b6-c83bec6b4cc4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proyecto creado manualmente.\n",
            "total 16\n",
            "drwxr-xr-x 2 root root 4096 Jan 16 00:36 .\n",
            "drwxr-xr-x 1 root root 4096 Jan 16 00:36 ..\n",
            "-rw-r--r-- 1 root root  358 Jan 16 00:36 dbt_project.yml\n",
            "-rw-r--r-- 1 root root  138 Jan 16 00:36 profiles.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Ingest bronze\n",
        "\n",
        "\n",
        "db_path = '/content/sales_analytics/sales.duckdb'\n",
        "con = duckdb.connect(db_path)\n",
        "\n",
        "con.execute(\"CREATE SCHEMA IF NOT EXISTS bronze\")\n",
        "\n",
        "con.execute(\"CREATE OR REPLACE TABLE bronze.fact_sales AS SELECT * FROM read_csv_auto('/content/fact_sales.csv')\")\n",
        "con.execute(\"CREATE OR REPLACE TABLE bronze.dim_customer AS SELECT * FROM read_csv_auto('/content/dim_customer.csv')\")\n",
        "con.execute(\"CREATE OR REPLACE TABLE bronze.dim_product AS SELECT * FROM read_csv_auto('/content/dim_product.csv')\")\n",
        "con.execute(\"CREATE OR REPLACE TABLE bronze.dim_time AS SELECT * FROM read_csv_auto('/content/dim_time.csv')\")\n",
        "con.execute(\"CREATE OR REPLACE TABLE bronze.dim_location AS SELECT * FROM read_csv_auto('/content/dim_location.csv')\")\n",
        "\n",
        "con.close()\n",
        "print(\"Bronze cargado.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wmq7BrkqXiaC",
        "outputId": "b9382889-3fc8-4cfb-b071-1a2fcec52f58"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bronze cargado.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: sources.yml\n",
        "import os\n",
        "os.makedirs('models/sources', exist_ok=True)\n",
        "with open('models/sources/sources.yml', 'w') as f:\n",
        "    f.write(\"\"\"\n",
        "version: 2\n",
        "\n",
        "sources:\n",
        "  - name: bronze\n",
        "    schema: bronze\n",
        "    tables:\n",
        "      - name: fact_sales\n",
        "      - name: dim_customer\n",
        "      - name: dim_product\n",
        "      - name: dim_time\n",
        "      - name: dim_location\n",
        "\"\"\")\n",
        "print(\"sources.yml creado.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tijdSY_5Xmgm",
        "outputId": "09dad87c-3f40-4026-ebdb-60b6bb5420c0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sources.yml creado.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CelL 6: Silver models\n",
        "import os\n",
        "\n",
        "silver_dir = 'models/silver'\n",
        "os.makedirs(silver_dir, exist_ok=True)\n",
        "\n",
        "# silver_fact_sales.sql\n",
        "with open('models/silver/silver_fact_sales.sql', 'w') as f:\n",
        "    f.write(\"\"\"\n",
        "{{ config(materialized='incremental', unique_key='sale_id', incremental_strategy='delete+insert') }}\n",
        "\n",
        "SELECT\n",
        "    sale_id,\n",
        "    time_id,\n",
        "    customer_id,\n",
        "    product_id,\n",
        "    location_id,\n",
        "    quantity,\n",
        "    price,\n",
        "    discount,\n",
        "    tax_rate,\n",
        "    sale_timestamp,\n",
        "    revenue_before_discount,\n",
        "    revenue,\n",
        "    -- Cleaning\n",
        "    CASE WHEN quantity < 0 THEN 0 ELSE quantity END AS cleaned_quantity,\n",
        "    CASE WHEN location_id < 1 THEN 1 ELSE location_id END AS cleaned_location_id,  -- Fix invalid\n",
        "    CASE WHEN revenue <= 0 THEN revenue_before_discount ELSE revenue END AS cleaned_revenue\n",
        "FROM {{ source('bronze', 'fact_sales') }}\n",
        "{% if is_incremental() %}\n",
        "WHERE time_id > (SELECT MAX(time_id) FROM {{ this }})\n",
        "{% endif %}\n",
        "\"\"\")\n",
        "\n",
        "print(\"silver_fact_sales.sql actualizado con incremental_strategy='delete+insert'.\")\n",
        "\n",
        "# Silver dims\n",
        "dims = ['customer', 'product', 'time', 'location']\n",
        "for dim in dims:\n",
        "    with open(os.path.join(silver_dir, f'silver_dim_{dim}.sql'), 'w') as f:\n",
        "        f.write(\"\"\"\n",
        "{{ config(materialized='table') }}\n",
        "\n",
        "SELECT *\n",
        "FROM {{ source('bronze', 'dim_%s') }}\n",
        "\"\"\" % dim)\n",
        "\n",
        "print(\"silver models create.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ma0ZlIOMXy40",
        "outputId": "a05379b1-718f-4e6f-8c11-22016a22e20b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "silver_fact_sales.sql actualizado con incremental_strategy='delete+insert'.\n",
            "silver models create.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: Gold models\n",
        "import os\n",
        "\n",
        "gold_dir = 'models/gold'\n",
        "os.makedirs(gold_dir, exist_ok=True)\n",
        "\n",
        "with open(os.path.join(gold_dir, 'gold_fact_sales_aggregated.sql'), 'w') as f:\n",
        "    f.write(\"\"\"\n",
        "{{ config(materialized='table') }}\n",
        "\n",
        "SELECT\n",
        "    t.date AS date_key,\n",
        "    l.region AS region,\n",
        "    c.segment AS customer_segment,\n",
        "    p.category AS product_category,\n",
        "    SUM(f.cleaned_quantity) AS total_quantity,\n",
        "    SUM(f.cleaned_revenue) AS total_revenue,\n",
        "    AVG(f.discount) AS avg_discount,\n",
        "    SUM(f.cleaned_revenue - (p.cost * f.cleaned_quantity)) AS total_profit\n",
        "FROM {{ ref('silver_fact_sales') }} f\n",
        "JOIN {{ ref('silver_dim_time') }} t ON f.time_id = t.time_id\n",
        "JOIN {{ ref('silver_dim_location') }} l ON f.cleaned_location_id = l.location_id\n",
        "JOIN {{ ref('silver_dim_customer') }} c ON f.customer_id = c.customer_id\n",
        "JOIN {{ ref('silver_dim_product') }} p ON f.product_id = p.product_id\n",
        "GROUP BY 1, 2, 3, 4\n",
        "\"\"\")\n",
        "\n",
        "with open(os.path.join(gold_dir, 'gold_monthly_revenue_yoy.sql'), 'w') as f:\n",
        "    f.write(\"\"\"\n",
        "{{ config(materialized='view') }}\n",
        "\n",
        "WITH monthly AS (\n",
        "    SELECT\n",
        "        t.year || '-' || LPAD(t.month::TEXT, 2, '0') AS month_key,\n",
        "        l.region,\n",
        "        SUM(f.cleaned_revenue) AS revenue\n",
        "    FROM {{ ref('silver_fact_sales') }} f\n",
        "JOIN {{ ref('silver_dim_time') }} t ON f.time_id = t.time_id\n",
        "JOIN {{ ref('silver_dim_location') }} l ON f.cleaned_location_id = l.location_id\n",
        "GROUP BY 1, 2\n",
        ")\n",
        "SELECT\n",
        "    month_key,\n",
        "    region,\n",
        "    revenue,\n",
        "    LAG(revenue) OVER (PARTITION BY region ORDER BY month_key) AS prev_revenue,\n",
        "    (revenue - LAG(revenue) OVER (PARTITION BY region ORDER BY month_key)) / NULLIF(LAG(revenue) OVER (PARTITION BY region ORDER BY month_key), 0) * 100 AS yoy_growth\n",
        "FROM monthly\n",
        "\"\"\")\n",
        "\n",
        "print(\"Gold models Create.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTRil6ltX2Q9",
        "outputId": "4779ed56-b5fb-48b8-a04c-ff8a308db9ad"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gold models Create.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8: Tests dbt\n",
        "with open('models/schema.yml', 'w') as f:\n",
        "    f.write(\"\"\"\n",
        "version: 2\n",
        "\n",
        "models:\n",
        "  - name: silver_fact_sales\n",
        "    columns:\n",
        "      - name: sale_id\n",
        "        tests:\n",
        "          - unique\n",
        "          - not_null\n",
        "      - name: cleaned_quantity\n",
        "        tests:\n",
        "          - dbt_utils.expression_is_true:\n",
        "              expression: \">= 0\"\n",
        "      - name: discount\n",
        "        tests:\n",
        "          - dbt_utils.expression_is_true:\n",
        "              expression: \"BETWEEN 0 AND 1\"\n",
        "      - name: cleaned_revenue\n",
        "        tests:\n",
        "          - dbt_utils.expression_is_true:\n",
        "              expression: \"> 0\"\n",
        "\"\"\")\n",
        "\n",
        "print(\"schema.yml actualizado con sintaxis correcta.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzvlISBSX7dc",
        "outputId": "54b59101-1a3a-4152-aa8a-2d913117fe5d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "schema.yml actualizado con sintaxis correcta.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9:  Packages (dbt_utils)\n",
        "with open('packages.yml', 'w') as f:\n",
        "    f.write(\"\"\"\n",
        "packages:\n",
        "  - package: dbt-labs/dbt_utils\n",
        "    version: 1.1.1\n",
        "\"\"\")\n",
        "\n",
        "!dbt deps\n",
        "print(\"dbt_utils instalado.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-hmEFugX-j4",
        "outputId": "4a46b960-13fd-4d1d-82be-6fcb58843266"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m00:36:14  Running with dbt=1.11.2\n",
            "\u001b[0m00:36:15  Updating lock file in file path: /content/sales_analytics/package-lock.yml\n",
            "\u001b[0m00:36:15  Installing dbt-labs/dbt_utils\n",
            "\u001b[0m00:36:15  Installed from version 1.1.1\n",
            "\u001b[0m00:36:15  Updated version available: 1.3.3\n",
            "\u001b[0m00:36:15  \n",
            "\u001b[0m00:36:15  Updates available for packages: ['dbt-labs/dbt_utils']                 \n",
            "Update your versions in packages.yml, then run dbt deps\n",
            "dbt_utils instalado.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 10: Run dbt (with cleanup)\n",
        "# 1. Clean up previous builds\n",
        "\n",
        "!rm -rf target dbt_packages\n",
        "\n",
        "# 2. Verify Configuration\n",
        "!dbt debug\n",
        "\n",
        "# 3. Install dependencies (after cleanup)\n",
        "!dbt deps\n",
        "\n",
        "# 4. Execute Models\n",
        "!dbt run\n",
        "\n",
        "# 5. Execute Tests\n",
        "!dbt test\n",
        "\n",
        "# 6. Generate Documentation\n",
        "!dbt docs generate\n",
        "\n",
        "\n",
        "# 7. Compress the target folder to dowload it\n",
        "!zip -r dbt_docs.zip target\n",
        "\n",
        "# 8. Dowload the Zip ;)\n",
        "from google.colab import files\n",
        "files.download('dbt_docs.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RRncI1SKYFG1",
        "outputId": "a49ee0f5-ec15-41ad-ba07-d72cb722b6bc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m00:38:24  Running with dbt=1.11.2\n",
            "\u001b[0m00:38:24  dbt version: 1.11.2\n",
            "\u001b[0m00:38:24  python version: 3.12.12\n",
            "\u001b[0m00:38:24  python path: /usr/bin/python3\n",
            "\u001b[0m00:38:24  os info: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "\u001b[0m00:38:24  Using profiles dir at /content/sales_analytics\n",
            "\u001b[0m00:38:24  Using profiles.yml file at /content/sales_analytics/profiles.yml\n",
            "\u001b[0m00:38:24  Using dbt_project.yml file at /content/sales_analytics/dbt_project.yml\n",
            "\u001b[0m00:38:24  adapter type: duckdb\n",
            "\u001b[0m00:38:24  adapter version: 1.10.0\n",
            "\u001b[0m00:38:24  Configuration:\n",
            "\u001b[0m00:38:24    profiles.yml file [\u001b[32mOK found and valid\u001b[0m]\n",
            "\u001b[0m00:38:24    dbt_project.yml file [\u001b[32mOK found and valid\u001b[0m]\n",
            "\u001b[0m00:38:24  Required dependencies:\n",
            "\u001b[0m00:38:24   - git [\u001b[32mOK found\u001b[0m]\n",
            "\n",
            "\u001b[0m00:38:24  Connection:\n",
            "\u001b[0m00:38:24    database: sales\n",
            "\u001b[0m00:38:24    schema: main\n",
            "\u001b[0m00:38:24    path: /content/sales_analytics/sales.duckdb\n",
            "\u001b[0m00:38:24    config_options: None\n",
            "\u001b[0m00:38:24    extensions: None\n",
            "\u001b[0m00:38:24    settings: {}\n",
            "\u001b[0m00:38:24    external_root: .\n",
            "\u001b[0m00:38:24    use_credential_provider: None\n",
            "\u001b[0m00:38:24    attach: None\n",
            "\u001b[0m00:38:24    filesystems: None\n",
            "\u001b[0m00:38:24    remote: None\n",
            "\u001b[0m00:38:24    plugins: None\n",
            "\u001b[0m00:38:24    disable_transactions: False\n",
            "\u001b[0m00:38:24  Registered adapter: duckdb=1.10.0\n",
            "\u001b[0m00:38:25    Connection test: [\u001b[32mOK connection ok\u001b[0m]\n",
            "\n",
            "\u001b[0m00:38:25  \u001b[32mAll checks passed!\u001b[0m\n",
            "\u001b[0m00:38:29  Running with dbt=1.11.2\n",
            "\u001b[0m00:38:30  Installing dbt-labs/dbt_utils\n",
            "\u001b[0m00:38:30  Installed from version 1.1.1\n",
            "\u001b[0m00:38:30  Updated version available: 1.3.3\n",
            "\u001b[0m00:38:30  \n",
            "\u001b[0m00:38:30  Updates available for packages: ['dbt-labs/dbt_utils']                 \n",
            "Update your versions in packages.yml, then run dbt deps\n",
            "\u001b[0m00:38:35  Running with dbt=1.11.2\n",
            "\u001b[0m00:38:36  Registered adapter: duckdb=1.10.0\n",
            "\u001b[0m00:38:36  Unable to do partial parsing because saved manifest not found. Starting full parse.\n",
            "\u001b[0m00:38:38  [\u001b[33mWARNING\u001b[0m][MissingArgumentsPropertyInGenericTestDeprecation]: Deprecated\n",
            "functionality\n",
            "Found top-level arguments to test `dbt_utils.expression_is_true` defined on\n",
            "'silver_fact_sales' in package 'sales_analytics' (models/schema.yml). Arguments\n",
            "to generic tests should be nested under the `arguments` property.\n",
            "\u001b[0m00:38:38  Found 7 models, 5 data tests, 5 sources, 586 macros\n",
            "\u001b[0m00:38:38  \n",
            "\u001b[0m00:38:38  Concurrency: 4 threads (target='dev')\n",
            "\u001b[0m00:38:38  \n",
            "\u001b[0m00:38:38  1 of 7 START sql table model main.silver_dim_customer .......................... [RUN]\n",
            "\u001b[0m00:38:38  3 of 7 START sql table model main.silver_dim_product ........................... [RUN]\n",
            "\u001b[0m00:38:38  2 of 7 START sql table model main.silver_dim_location .......................... [RUN]\n",
            "\u001b[0m00:38:38  4 of 7 START sql table model main.silver_dim_time .............................. [RUN]\n",
            "\u001b[0m00:38:39  2 of 7 OK created sql table model main.silver_dim_location ..................... [\u001b[32mOK\u001b[0m in 0.21s]\n",
            "\u001b[0m00:38:39  4 of 7 OK created sql table model main.silver_dim_time ......................... [\u001b[32mOK\u001b[0m in 0.21s]\n",
            "\u001b[0m00:38:39  3 of 7 OK created sql table model main.silver_dim_product ...................... [\u001b[32mOK\u001b[0m in 0.25s]\n",
            "\u001b[0m00:38:39  5 of 7 START sql incremental model main.silver_fact_sales ...................... [RUN]\n",
            "\u001b[0m00:38:39  1 of 7 OK created sql table model main.silver_dim_customer ..................... [\u001b[32mOK\u001b[0m in 0.26s]\n",
            "\u001b[0m00:38:39  5 of 7 OK created sql incremental model main.silver_fact_sales ................. [\u001b[32mOK\u001b[0m in 0.09s]\n",
            "\u001b[0m00:38:39  6 of 7 START sql table model main.gold_fact_sales_aggregated ................... [RUN]\n",
            "\u001b[0m00:38:39  7 of 7 START sql view model main.gold_monthly_revenue_yoy ...................... [RUN]\n",
            "\u001b[0m00:38:39  7 of 7 OK created sql view model main.gold_monthly_revenue_yoy ................. [\u001b[32mOK\u001b[0m in 0.10s]\n",
            "\u001b[0m00:38:39  6 of 7 OK created sql table model main.gold_fact_sales_aggregated .............. [\u001b[32mOK\u001b[0m in 0.12s]\n",
            "\u001b[0m00:38:39  \n",
            "\u001b[0m00:38:39  Finished running 1 incremental model, 5 table models, 1 view model in 0 hours 0 minutes and 0.63 seconds (0.63s).\n",
            "\u001b[0m00:38:39  \n",
            "\u001b[0m00:38:39  \u001b[32mCompleted successfully\u001b[0m\n",
            "\u001b[0m00:38:39  \n",
            "\u001b[0m00:38:39  Done. PASS=7 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=7\n",
            "\u001b[0m00:38:39  [\u001b[33mWARNING\u001b[0m][DeprecationsSummary]: Deprecated functionality\n",
            "Summary of encountered deprecations:\n",
            "- MissingArgumentsPropertyInGenericTestDeprecation: 3 occurrences\n",
            "To see all deprecation instances instead of just the first occurrence of each,\n",
            "run command again with the `--show-all-deprecations` flag. You may also need to\n",
            "run with `--no-partial-parse` as some deprecations are only encountered during\n",
            "parsing.\n",
            "\u001b[0m00:38:44  Running with dbt=1.11.2\n",
            "\u001b[0m00:38:45  Registered adapter: duckdb=1.10.0\n",
            "\u001b[0m00:38:46  Found 7 models, 5 data tests, 5 sources, 586 macros\n",
            "\u001b[0m00:38:46  \n",
            "\u001b[0m00:38:46  Concurrency: 4 threads (target='dev')\n",
            "\u001b[0m00:38:46  \n",
            "\u001b[0m00:38:46  1 of 5 START test dbt_utils_expression_is_true_silver_fact_sales_cleaned_quantity___0  [RUN]\n",
            "\u001b[0m00:38:46  2 of 5 START test dbt_utils_expression_is_true_silver_fact_sales_cleaned_revenue___0  [RUN]\n",
            "\u001b[0m00:38:46  3 of 5 START test dbt_utils_expression_is_true_silver_fact_sales_discount__BETWEEN_0_AND_1  [RUN]\n",
            "\u001b[0m00:38:46  4 of 5 START test not_null_silver_fact_sales_sale_id ........................... [RUN]\n",
            "\u001b[0m00:38:46  2 of 5 PASS dbt_utils_expression_is_true_silver_fact_sales_cleaned_revenue___0 . [\u001b[32mPASS\u001b[0m in 0.13s]\n",
            "\u001b[0m00:38:46  1 of 5 PASS dbt_utils_expression_is_true_silver_fact_sales_cleaned_quantity___0  [\u001b[32mPASS\u001b[0m in 0.14s]\n",
            "\u001b[0m00:38:46  3 of 5 PASS dbt_utils_expression_is_true_silver_fact_sales_discount__BETWEEN_0_AND_1  [\u001b[32mPASS\u001b[0m in 0.13s]\n",
            "\u001b[0m00:38:46  4 of 5 PASS not_null_silver_fact_sales_sale_id ................................. [\u001b[32mPASS\u001b[0m in 0.11s]\n",
            "\u001b[0m00:38:46  5 of 5 START test unique_silver_fact_sales_sale_id ............................. [RUN]\n",
            "\u001b[0m00:38:46  5 of 5 PASS unique_silver_fact_sales_sale_id ................................... [\u001b[32mPASS\u001b[0m in 0.03s]\n",
            "\u001b[0m00:38:46  \n",
            "\u001b[0m00:38:46  Finished running 5 data tests in 0 hours 0 minutes and 0.30 seconds (0.30s).\n",
            "\u001b[0m00:38:46  \n",
            "\u001b[0m00:38:46  \u001b[32mCompleted successfully\u001b[0m\n",
            "\u001b[0m00:38:46  \n",
            "\u001b[0m00:38:46  Done. PASS=5 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=5\n",
            "\u001b[0m00:38:50  Running with dbt=1.11.2\n",
            "\u001b[0m00:38:51  Registered adapter: duckdb=1.10.0\n",
            "\u001b[0m00:38:51  Found 7 models, 5 data tests, 5 sources, 586 macros\n",
            "\u001b[0m00:38:51  \n",
            "\u001b[0m00:38:51  Concurrency: 4 threads (target='dev')\n",
            "\u001b[0m00:38:51  \n",
            "\u001b[0m00:38:52  Building catalog\n",
            "\u001b[0m00:38:52  Catalog written to /content/sales_analytics/target/catalog.json\n",
            "  adding: target/ (stored 0%)\n",
            "  adding: target/index.html (deflated 73%)\n",
            "  adding: target/partial_parse.msgpack (deflated 85%)\n",
            "  adding: target/semantic_manifest.json (deflated 45%)\n",
            "  adding: target/graph.gpickle (deflated 77%)\n",
            "  adding: target/compiled/ (stored 0%)\n",
            "  adding: target/compiled/sales_analytics/ (stored 0%)\n",
            "  adding: target/compiled/sales_analytics/models/ (stored 0%)\n",
            "  adding: target/compiled/sales_analytics/models/schema.yml/ (stored 0%)\n",
            "  adding: target/compiled/sales_analytics/models/schema.yml/dbt_utils_expression_is_true_s_1128924b3db40e81d5f55a18a3c89e04.sql (deflated 9%)\n",
            "  adding: target/compiled/sales_analytics/models/schema.yml/dbt_utils_expression_is_true_s_6f39fe063d3bb39ea6b025c38f6fac44.sql (deflated 10%)\n",
            "  adding: target/compiled/sales_analytics/models/schema.yml/dbt_utils_expression_is_true_s_6652992a83cefec692783bb106eab889.sql (deflated 5%)\n",
            "  adding: target/compiled/sales_analytics/models/schema.yml/not_null_silver_fact_sales_sale_id.sql (deflated 20%)\n",
            "  adding: target/compiled/sales_analytics/models/schema.yml/unique_silver_fact_sales_sale_id.sql (deflated 30%)\n",
            "  adding: target/compiled/sales_analytics/models/gold/ (stored 0%)\n",
            "  adding: target/compiled/sales_analytics/models/gold/gold_fact_sales_aggregated.sql (deflated 57%)\n",
            "  adding: target/compiled/sales_analytics/models/gold/gold_monthly_revenue_yoy.sql (deflated 54%)\n",
            "  adding: target/compiled/sales_analytics/models/silver/ (stored 0%)\n",
            "  adding: target/compiled/sales_analytics/models/silver/silver_fact_sales.sql (deflated 54%)\n",
            "  adding: target/compiled/sales_analytics/models/silver/silver_dim_customer.sql (stored 0%)\n",
            "  adding: target/compiled/sales_analytics/models/silver/silver_dim_location.sql (stored 0%)\n",
            "  adding: target/compiled/sales_analytics/models/silver/silver_dim_time.sql (stored 0%)\n",
            "  adding: target/compiled/sales_analytics/models/silver/silver_dim_product.sql (stored 0%)\n",
            "  adding: target/catalog.json (deflated 90%)\n",
            "  adding: target/manifest.json (deflated 88%)\n",
            "  adding: target/graph_summary.json (deflated 75%)\n",
            "  adding: target/run_results.json (deflated 78%)\n",
            "  adding: target/run/ (stored 0%)\n",
            "  adding: target/run/sales_analytics/ (stored 0%)\n",
            "  adding: target/run/sales_analytics/models/ (stored 0%)\n",
            "  adding: target/run/sales_analytics/models/schema.yml/ (stored 0%)\n",
            "  adding: target/run/sales_analytics/models/schema.yml/dbt_utils_expression_is_true_s_1128924b3db40e81d5f55a18a3c89e04.sql (deflated 43%)\n",
            "  adding: target/run/sales_analytics/models/schema.yml/dbt_utils_expression_is_true_s_6f39fe063d3bb39ea6b025c38f6fac44.sql (deflated 44%)\n",
            "  adding: target/run/sales_analytics/models/schema.yml/dbt_utils_expression_is_true_s_6652992a83cefec692783bb106eab889.sql (deflated 42%)\n",
            "  adding: target/run/sales_analytics/models/schema.yml/not_null_silver_fact_sales_sale_id.sql (deflated 47%)\n",
            "  adding: target/run/sales_analytics/models/schema.yml/unique_silver_fact_sales_sale_id.sql (deflated 48%)\n",
            "  adding: target/run/sales_analytics/models/gold/ (stored 0%)\n",
            "  adding: target/run/sales_analytics/models/gold/gold_fact_sales_aggregated.sql (deflated 57%)\n",
            "  adding: target/run/sales_analytics/models/gold/gold_monthly_revenue_yoy.sql (deflated 54%)\n",
            "  adding: target/run/sales_analytics/models/silver/ (stored 0%)\n",
            "  adding: target/run/sales_analytics/models/silver/silver_fact_sales.sql (deflated 54%)\n",
            "  adding: target/run/sales_analytics/models/silver/silver_dim_customer.sql (deflated 30%)\n",
            "  adding: target/run/sales_analytics/models/silver/silver_dim_location.sql (deflated 29%)\n",
            "  adding: target/run/sales_analytics/models/silver/silver_dim_time.sql (deflated 28%)\n",
            "  adding: target/run/sales_analytics/models/silver/silver_dim_product.sql (deflated 29%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f2924549-e57b-45f3-93be-7443b4fd90d6\", \"dbt_docs.zip\", 668605)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Great Expectations â€“ ValidaciÃ³n de Calidad de Datos** ğŸ±â€ğŸ‘¤ğŸ’½ğŸ“‹\n",
        "\n",
        "\n",
        "> Here we implement **Great Expectations** on top of the dbt-transformed gold layers to enforce data quality rules.  \n",
        "\n",
        "> The validation intentionally fails on synthetic anomalies (negative values, invalid keys, zero metrics), showcasing proactive governance, error detection, and alignment with Medallion Architecture best practices.\n",
        "\n"
      ],
      "metadata": {
        "id": "5UiMGJqtDBbN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show great-expectations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqA7WOKax0m5",
        "outputId": "b55a8fcf-737d-413f-f89d-bfc0dcd6db77"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: great_expectations\n",
            "Version: 1.11.0\n",
            "Summary: Always know what to expect from your data.\n",
            "Home-page: https://greatexpectations.io\n",
            "Author: The Great Expectations Team\n",
            "Author-email: team@greatexpectations.io\n",
            "License: Apache-2.0\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: altair, cryptography, jinja2, jsonschema, marshmallow, mistune, numpy, packaging, pandas, pydantic, pyparsing, python-dateutil, requests, ruamel.yaml, scipy, tqdm, typing-extensions, tzlocal\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 11: Great Expectations\n",
        "import great_expectations as gx\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# 1.Prepare the data\n",
        "df_fact_sales = pd.read_csv('/content/fact_sales.csv')\n",
        "if 'sale_timestamp' in df_fact_sales.columns:\n",
        "    df_fact_sales['sale_timestamp'] = pd.to_datetime(df_fact_sales['sale_timestamp'])\n",
        "\n",
        "# 2. Inicialize the context\n",
        "context = gx.get_context()\n",
        "\n",
        "# 3. Cofigure Datasource And the Asset\n",
        "datasource_name = \"erp_datasource\"\n",
        "try:\n",
        "    context.data_sources.delete(datasource_name)\n",
        "except:\n",
        "    pass\n",
        "\n",
        "datasource = context.data_sources.add_pandas(name=datasource_name)\n",
        "data_asset = datasource.add_dataframe_asset(name=\"fact_sales_asset\")\n",
        "\n",
        "# --- KEy STEPğŸ‘€ GX 1.11: Crear el Batch Definition ---\n",
        "batch_def_name = \"fact_sales_batch_def\"\n",
        "#The Asset now generates the lot definition\n",
        "batch_definition = data_asset.add_batch_definition_whole_dataframe(name=batch_def_name)\n",
        "\n",
        "# 4. Configure the Expectation Suite\n",
        "suite_name = \"erp_quality_suite_advanced\"\n",
        "try:\n",
        "    context.suites.delete(suite_name)\n",
        "except:\n",
        "    pass\n",
        "\n",
        "suite = context.suites.add(gx.ExpectationSuite(name=suite_name))\n",
        "\n",
        "# 5. Add the Expectations\n",
        "suite.add_expectation(gx.expectations.ExpectColumnValuesToNotBeNull(column=\"sale_id\"))\n",
        "suite.add_expectation(gx.expectations.ExpectColumnValuesToBeUnique(column=\"sale_id\"))\n",
        "suite.add_expectation(gx.expectations.ExpectColumnValuesToBeBetween(column=\"quantity\", min_value=-10, max_value=10000))\n",
        "suite.add_expectation(gx.expectations.ExpectColumnValuesToBeBetween(column=\"price\", min_value=0, max_value=10000000))\n",
        "suite.add_expectation(gx.expectations.ExpectColumnValuesToBeBetween(column=\"discount\", min_value=0, max_value=0.5))\n",
        "suite.add_expectation(gx.expectations.ExpectColumnValuesToBeBetween(column=\"tax_rate\", min_value=0.01, max_value=0.2))\n",
        "suite.add_expectation(gx.expectations.ExpectColumnMeanToBeBetween(column=\"revenue\", min_value=0, max_value=10000))\n",
        "suite.add_expectation(gx.expectations.ExpectCompoundColumnsToBeUnique(column_list=[\"sale_id\", \"time_id\"]))\n",
        "suite.add_expectation(gx.expectations.ExpectTableRowCountToBeBetween(min_value=5000, max_value=110000))\n",
        "\n",
        "# 6.VALIDATION DEFINITION (Now using BatchDefinition)\n",
        "validation_def_name = \"erp_validation\"\n",
        "try:\n",
        "    context.validation_definitions.delete(validation_def_name)\n",
        "except:\n",
        "    pass\n",
        "\n",
        "validation_definition = context.validation_definitions.add(\n",
        "    gx.ValidationDefinition(\n",
        "        name=validation_def_name,\n",
        "        data=batch_definition,  # <-- BatchDefinition\n",
        "        suite=suite\n",
        "    )\n",
        ")\n",
        "\n",
        "# 7. Creaate Checkpoint y execute\n",
        "checkpoint_name = \"erp_checkpoint\"\n",
        "try:\n",
        "    context.checkpoints.delete(checkpoint_name)\n",
        "except:\n",
        "    pass\n",
        "\n",
        "checkpoint = context.checkpoints.add(\n",
        "    gx.Checkpoint(\n",
        "        name=checkpoint_name,\n",
        "        validation_definitions=[validation_definition]\n",
        "    )\n",
        ")\n",
        "\n",
        "#\n",
        "results = checkpoint.run(batch_parameters={\"dataframe\": df_fact_sales})\n",
        "\n",
        "# 8. Show the results\n",
        "print(f\"\\nÂ¿Validation succesfull?: {results.success}\")\n",
        "\n",
        "# 9. Data Docs\n",
        "context.build_data_docs()\n",
        "docs_path = context.get_docs_sites_urls()[0][\"site_url\"]\n",
        "print(f\"Generate Repor: {docs_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312,
          "referenced_widgets": [
            "da9442185a944641a2315e8dbfe8af74",
            "502ba005710b4413808d025d05bb6519",
            "6c3c8962073a4a82900f7e1c6cd14ef2",
            "89eae199bdff41e48ea624f461457967",
            "e07a1fde00ba42b3a72a88911053d10f",
            "f6f8cc529591484996f483c4fa819cc9",
            "6dd4f37430454e3c8d68df8f98600af0",
            "6f4034c147ff480c91f9900ab58822ee",
            "d5253076ab144daea5cf3f07a026b5f5",
            "bcac71ee2393441ab33e5268b3df5d25",
            "1ae89111cd5348a88dcbb984e9a3d10a"
          ]
        },
        "id": "o6EACuE81HSi",
        "outputId": "7693f968-0195-4541-ec32-681c3d292e4d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:great_expectations.data_context.types.base:Created temporary directory '/tmp/tmpvwna2qn3' for ephemeral docs site\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Calculating Metrics:   0%|          | 0/49 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "da9442185a944641a2315e8dbfe8af74"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Â¿Validation succesfull?: True\n",
            "Generate Repor: file:///tmp/tmpvwna2qn3/index.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 11: Compress and dowload Data Docs\n",
        "!zip -r gx_data_docs.zip /tmp/tmpvwna2qn3/index.html  # Ajusta el nombre si es diferente (mira el INFO)\n",
        "from google.colab import files\n",
        "files.download('gx_data_docs.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "7qJIJWP_20Kz",
        "outputId": "b8b346e7-74b2-4dab-e684-a98bb032e1e4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: tmp/tmpvwna2qn3/index.html (deflated 73%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4ddd7e86-b6b6-4be1-ad10-3e29300db1b0\", \"gx_data_docs.zip\", 5365)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Cell 12:\n",
        "# Show details of each expectation (failed and successful)\n",
        "print(\"\\n=== Detalles de Expectations ===\")\n",
        "\n",
        "# 'results' is a CheckpointResult object\n",
        "# Iterate through each ValidationResult within the CheckpointResult\n",
        "for validation_id, validation_result_obj in results.run_results.items():\n",
        "    print(f\"\\n--- EjecuciÃ³n de ValidaciÃ³n: {validation_id.run_id.run_name} ---\")\n",
        "    print(f\"  Ã‰xito General: {validation_result_obj.success}\")\n",
        "\n",
        "\n",
        "   # iterate trhough each ExpectationValidationResult within the ValidationResult\n",
        "    for evr in validation_result_obj.results:\n",
        "        # Correctly accessing the type of expectation and individual success\n",
        "        exp_type = evr.expectation_config.type\n",
        "        success = evr.success\n",
        "\n",
        "        if not success:\n",
        "            print(f\"\\n[FALLÃ“] {exp_type}\")\n",
        "            print(f\"   - Columna: {evr.expectation_config.kwargs.get('column', 'N/A')}\")\n",
        "            print(f\"   - Conteo inesperado: {evr.result.get('unexpected_count', 'N/A')}\")\n",
        "            print(f\"   - Valor observado: {evr.result.get('observed_value', 'N/A')}\")\n",
        "            print(f\"   - Detalles: {evr.result.get('details', 'N/A')}\")\n",
        "        else:\n",
        "            print(f\"[PASÃ“] {exp_type}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fVOh4E84Y5X",
        "outputId": "f1296a2b-def2-48f4-9894-7146931a55a0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Detalles de Expectations ===\n",
            "\n",
            "--- EjecuciÃ³n de ValidaciÃ³n: None ---\n",
            "  Ã‰xito General: True\n",
            "[PASÃ“] expect_column_values_to_not_be_null\n",
            "[PASÃ“] expect_column_values_to_be_unique\n",
            "[PASÃ“] expect_column_values_to_be_between\n",
            "[PASÃ“] expect_column_values_to_be_between\n",
            "[PASÃ“] expect_column_values_to_be_between\n",
            "[PASÃ“] expect_column_values_to_be_between\n",
            "[PASÃ“] expect_column_mean_to_be_between\n",
            "[PASÃ“] expect_compound_columns_to_be_unique\n",
            "[PASÃ“] expect_table_row_count_to_be_between\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7. Download Gold Layers**"
      ],
      "metadata": {
        "id": "n9T0V__RGvyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create Folder for exporting Gold Layers\n",
        "export_dir = '/content/golden_export'\n",
        "os.makedirs(export_dir, exist_ok=True)\n",
        "print(f\"Folder for exporting gold layers: {export_dir}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHXFuYI0877P",
        "outputId": "d3a58d8c-713e-4ce6-db5a-297cf74b9d57"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder for exporting gold layers: /content/golden_export\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Conect DuckDB (your actual path)\n",
        "con = duckdb.connect('/content/sales_analytics/sales.duckdb')\n",
        "\n",
        "# Gold model list\n",
        "gold_models = [\n",
        "    'gold_fact_sales_aggregated',\n",
        "    'gold_monthly_revenue_yoy'\n",
        "\n",
        "]\n",
        "\n",
        "for model_name in gold_models:\n",
        "    # Export to Parquet\n",
        "    parquet_path = f'{export_dir}/{model_name}.parquet'\n",
        "    con.execute(f\"COPY {model_name} TO '{parquet_path}' (FORMAT PARQUET)\")\n",
        "\n",
        "    # Exporta to CSV\n",
        "    csv_path = f'{export_dir}/{model_name}.csv'\n",
        "    con.execute(f\"COPY {model_name} TO '{csv_path}' (FORMAT CSV, HEADER, DELIMITER ',')\")\n",
        "\n",
        "    print(f\"Export: {model_name}\")\n",
        "    print(f\"  â†’ Parquet: {parquet_path}\")\n",
        "    print(f\"  â†’ CSV: {csv_path}\")\n",
        "\n",
        "print(\"\\nÂ¡Export Complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlSuw6s18VHR",
        "outputId": "487a1148-8099-44c3-93b7-fdd498e1a7ac"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Export: gold_fact_sales_aggregated\n",
            "  â†’ Parquet: /content/golden_export/gold_fact_sales_aggregated.parquet\n",
            "  â†’ CSV: /content/golden_export/gold_fact_sales_aggregated.csv\n",
            "Export: gold_monthly_revenue_yoy\n",
            "  â†’ Parquet: /content/golden_export/gold_monthly_revenue_yoy.parquet\n",
            "  â†’ CSV: /content/golden_export/gold_monthly_revenue_yoy.csv\n",
            "\n",
            "Â¡Export Complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List files generated\n",
        "!ls -lh /content/golden_export\n",
        "\n",
        "# Compress and Download folder\n",
        "!zip -r golden_export.zip /content/golden_export\n",
        "from google.colab import files\n",
        "files.download('golden_export.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "JZ0oFBYn9rI6",
        "outputId": "ddfe7ce1-b7e4-414d-9c11-7edf193bfa9e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 884K\n",
            "-rw-r--r-- 1 root root 680K Jan 16 00:40 gold_fact_sales_aggregated.csv\n",
            "-rw-r--r-- 1 root root 181K Jan 16 00:40 gold_fact_sales_aggregated.parquet\n",
            "-rw-r--r-- 1 root root  12K Jan 16 00:40 gold_monthly_revenue_yoy.csv\n",
            "-rw-r--r-- 1 root root 7.0K Jan 16 00:40 gold_monthly_revenue_yoy.parquet\n",
            "  adding: content/golden_export/ (stored 0%)\n",
            "  adding: content/golden_export/gold_monthly_revenue_yoy.parquet (deflated 36%)\n",
            "  adding: content/golden_export/gold_monthly_revenue_yoy.csv (deflated 63%)\n",
            "  adding: content/golden_export/gold_fact_sales_aggregated.csv (deflated 74%)\n",
            "  adding: content/golden_export/gold_fact_sales_aggregated.parquet (deflated 14%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_dcc2a8d5-d2af-4a0b-9405-f38f08bc22b1\", \"golden_export.zip\", 353002)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ruta de tu proyecto dbt\n",
        "project_folder = '/content/sales_analytics'\n",
        "\n",
        "# Nombre del archivo ZIP final\n",
        "zip_filename = 'sales_analytics_complete.zip'\n",
        "\n",
        "# Comprimir toda la carpeta\n",
        "!zip -r {zip_filename} {project_folder}\n",
        "\n",
        "# Descargar el ZIP automÃ¡ticamente\n",
        "files.download(zip_filename)\n",
        "\n",
        "print(f\"Descargando {zip_filename}...\")\n",
        "print(\"Contenido incluido:\")\n",
        "!ls -R {project_folder} | head -n 30  # Muestra los primeros 30 items para verificar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zRKn5PcIHDQO",
        "outputId": "558eb53d-6028-4a88-982a-db38096bc35e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/sales_analytics/ (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_packages/ (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/ (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/CONTRIBUTING.md (deflated 58%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/docker-compose.yml (deflated 21%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/macros/ (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/macros/web/ (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/macros/web/get_url_parameter.sql (deflated 55%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/macros/web/get_url_host.sql (deflated 59%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/macros/web/get_url_path.sql (deflated 61%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/macros/sql/ (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/macros/sql/unpivot.sql (deflated 63%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/macros/sql/generate_surrogate_key.sql (deflated 57%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/macros/sql/nullcheck_table.sql (deflated 56%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/macros/sql/get_single_value.sql (deflated 58%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/macros/sql/safe_divide.sql (deflated 47%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/macros/sql/star.sql (deflated 64%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/macros/sql/safe_subtract.sql (deflated 49%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/macros/sql/get_tables_by_pattern_sql.sql (deflated 72%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/macros/sql/nullcheck.sql (deflated 49%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/macros/sql/get_tables_by_prefix_sql.sql (deflated 61%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/macros/sql/deduplicate.sql (deflated 65%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/macros/sql/get_relations_by_pattern.sql (deflated 68%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/macros/sql/groupby.sql (deflated 38%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/macros/sql/get_table_types_sql.sql (deflated 76%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/macros/sql/safe_add.sql (deflated 49%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/macros/sql/get_filtered_columns_in_relation.sql (deflated 61%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/macros/sql/width_bucket.sql (deflated 64%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/macros/sql/date_spine.sql (deflated 66%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/macros/sql/get_query_results_as_dict.sql (deflated 57%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/macros/sql/haversine_distance.sql (deflated 67%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/macros/sql/union.sql (deflated 73%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/macros/sql/surrogate_key.sql (deflated 46%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/macros/sql/get_column_values.sql (deflated 64%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/macros/sql/generate_series.sql (deflated 66%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/macros/sql/pivot.sql (deflated 68%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/macros/sql/get_relations_by_prefix.sql (deflated 66%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/macros/generic_tests/ (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/macros/generic_tests/not_null_proportion.sql (deflated 62%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/macros/generic_tests/recency.sql (deflated 62%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/macros/generic_tests/equality.sql (deflated 61%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/macros/generic_tests/equal_rowcount.sql (deflated 62%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/macros/generic_tests/not_empty_string.sql (deflated 63%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/macros/generic_tests/accepted_range.sql (deflated 60%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/macros/generic_tests/at_least_one.sql (deflated 61%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/macros/generic_tests/fewer_rows_than.sql (deflated 66%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/macros/generic_tests/expression_is_true.sql (deflated 54%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/macros/generic_tests/unique_combination_of_columns.sql (deflated 61%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/macros/generic_tests/mutually_exclusive_ranges.sql (deflated 73%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/macros/generic_tests/not_accepted_values.sql (deflated 61%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/macros/generic_tests/sequential_values.sql (deflated 64%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/macros/generic_tests/cardinality_equality.sql (deflated 60%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/macros/generic_tests/not_constant.sql (deflated 55%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/macros/generic_tests/relationships_where.sql (deflated 59%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/macros/jinja_helpers/ (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/macros/jinja_helpers/pretty_time.sql (deflated 44%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/macros/jinja_helpers/pretty_log_format.sql (deflated 48%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/macros/jinja_helpers/_is_relation.sql (deflated 34%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/macros/jinja_helpers/log_info.sql (deflated 41%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/macros/jinja_helpers/_is_ephemeral.sql (deflated 56%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/macros/jinja_helpers/slugify.sql (deflated 49%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/tests/ (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/tests/conftest.py (deflated 73%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/tests/__init__.py (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/README.md (deflated 74%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/run_functional_test.sh (deflated 3%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/ (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/ci/ (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/ci/sample.profiles.yml (deflated 67%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/macros/ (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/macros/assert_equal_values.sql (deflated 54%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/macros/.gitkeep (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/macros/tests.sql (deflated 45%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/macros/limit_zero.sql (deflated 47%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/tests/ (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/tests/sql/ (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/tests/sql/test_get_column_values_use_default.sql (deflated 54%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/tests/sql/test_get_single_value_multiple_rows.sql (deflated 56%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/tests/generic/ (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/tests/generic/expect_table_columns_to_match_set.sql (deflated 65%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/tests/assert_get_query_results_as_dict_objects_equal.sql (deflated 68%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/tests/jinja_helpers/ (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/tests/jinja_helpers/test_slugify.sql (deflated 48%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/tests/jinja_helpers/assert_pretty_time_is_string.sql (deflated 37%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/tests/jinja_helpers/assert_pretty_output_msg_is_string.sql (deflated 37%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/README.md (deflated 62%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/ (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/web/ (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/web/schema.yml (deflated 72%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/web/test_urls.sql (deflated 51%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/web/test_url_host.sql (deflated 32%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/web/test_url_path.sql (deflated 36%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/sql/ (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/sql/test_pivot.sql (deflated 40%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/sql/schema.yml (deflated 85%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/sql/test_get_relations_by_prefix_and_union.sql (deflated 44%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/sql/test_get_column_values.sql (deflated 60%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/sql/test_union_no_source_column.sql (deflated 31%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/sql/test_union_base.sql (deflated 36%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/sql/test_safe_add.sql (deflated 28%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/sql/test_union_exclude_base_uppercase.sql (deflated 39%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/sql/test_get_relations_by_pattern.sql (deflated 45%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/sql/test_unpivot_bool.sql (deflated 47%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/sql/test_union_exclude_uppercase.sql (deflated 28%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/sql/test_star.sql (deflated 35%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/sql/test_get_filtered_columns_in_relation.sql (deflated 52%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/sql/test_union_where.sql (deflated 10%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/sql/test_star_uppercase.sql (deflated 31%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/sql/test_generate_series.sql (deflated 36%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/sql/test_groupby.sql (deflated 50%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/sql/test_not_empty_string_failing.sql (deflated 71%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/sql/test_star_aggregate.sql (deflated 42%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/sql/test_unpivot.sql (deflated 47%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/sql/test_union_exclude_base_lowercase.sql (deflated 39%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/sql/test_union_exclude_lowercase.sql (deflated 33%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/sql/test_union.sql (deflated 10%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/sql/test_safe_subtract.sql (deflated 31%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/sql/test_nullcheck_table.sql (deflated 55%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/sql/test_star_prefix_suffix.sql (deflated 45%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/sql/test_get_single_value_default.sql (deflated 62%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/sql/test_star_no_columns.sql (deflated 38%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/sql/test_not_empty_string_passing.sql (deflated 70%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/sql/test_get_single_value.sql (deflated 69%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/sql/test_union_where_base.sql (deflated 25%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/sql/test_safe_divide.sql (deflated 75%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/sql/test_pivot_apostrophe.sql (deflated 40%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/sql/test_get_column_values_where.sql (deflated 37%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/sql/test_star_quote_identifiers.sql (deflated 63%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/sql/test_generate_surrogate_key.sql (deflated 53%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/sql/test_deduplicate.sql (deflated 43%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/sql/test_width_bucket.sql (deflated 35%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/datetime/ (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/datetime/schema.yml (deflated 25%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/datetime/test_date_spine.sql (deflated 51%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/generic_tests/ (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/generic_tests/schema.yml (deflated 82%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/generic_tests/test_equal_rowcount.sql (deflated 19%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/generic_tests/recency_time_excluded.sql (deflated 45%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/generic_tests/test_equal_column_subset.sql (deflated 19%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/generic_tests/test_fewer_rows_than.sql (deflated 20%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/generic_tests/recency_time_included.sql (deflated 27%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/geo/ (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/geo/schema.yml (deflated 62%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/geo/test_haversine_distance_mi.sql (deflated 73%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/models/geo/test_haversine_distance_km.sql (deflated 58%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/dbt_project.yml (deflated 56%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/.gitignore (deflated 2%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/.env/ (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/.env/postgres.env (deflated 39%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/.env/redshift.env (deflated 51%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/.env/bigquery.env (deflated 8%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/.env/snowflake.env (deflated 52%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/packages.yml (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/ (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/web/ (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/web/data_urls.csv (deflated 47%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/web/data_url_path.csv (deflated 63%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/web/data_url_host.csv (deflated 49%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/schema_tests/ (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/schema_tests/data_test_equal_rowcount.csv (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/schema_tests/schema.yml (deflated 66%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/schema_tests/data_test_sequential_values.csv (deflated 7%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/schema_tests/data_test_relationships_where_table_1.csv (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/schema_tests/data_not_null_proportion.csv (deflated 4%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/schema_tests/data_test_mutually_exclusive_ranges_no_gaps.csv (deflated 14%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/schema_tests/data_test_fewer_rows_than_table_2.csv (deflated 11%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/schema_tests/data_cardinality_equality_a.csv (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/schema_tests/data_unique_combination_of_columns.csv (deflated 48%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/schema_tests/data_test_not_accepted_values.csv (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/schema_tests/data_cardinality_equality_b.csv (deflated 8%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/schema_tests/data_test_sequential_timestamps.csv (deflated 52%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/schema_tests/data_test_at_least_one.csv (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/schema_tests/data_test_mutually_exclusive_ranges_with_gaps_zero_length.csv (deflated 57%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/schema_tests/data_test_fewer_rows_than_table_1.csv (deflated 4%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/schema_tests/data_test_not_constant.csv (deflated 17%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/schema_tests/data_test_relationships_where_table_2.csv (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/schema_tests/data_test_mutually_exclusive_ranges_with_gaps.csv (deflated 39%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/schema_tests/data_test_accepted_range.csv (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/schema_tests/data_test_expression_is_true.csv (deflated 4%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/sql/ (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/sql/data_unpivot_expected.csv (deflated 54%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/sql/data_get_column_values_where_expected.csv (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/sql/data_get_single_value.csv (deflated 29%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/sql/data_pivot.csv (deflated 18%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/sql/data_nullcheck_table.csv (deflated 26%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/sql/data_star_expected.csv (deflated 7%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/sql/data_unpivot.csv (deflated 34%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/sql/data_get_column_values.csv (deflated 21%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/sql/data_safe_divide_numerator_expressions.csv (deflated 20%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/sql/data_star_prefix_suffix_expected.csv (deflated 40%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/sql/data_get_column_values_dropped.csv (deflated 21%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/sql/data_star_aggregate_expected.csv (deflated 26%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/sql/data_filtered_columns_in_relation.csv (deflated 17%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/sql/data_union_table_1.csv (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/sql/data_pivot_expected.csv (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/sql/data_filtered_columns_in_relation_expected.csv (deflated 11%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/sql/data_unpivot_original_api_expected.csv (deflated 59%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/sql/data_star_quote_identifiers.csv (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/sql/data_unpivot_bool_expected.csv (deflated 58%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/sql/data_deduplicate_expected.csv (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/sql/data_pivot_expected_apostrophe.csv (deflated 17%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/sql/data_get_column_values_where.csv (deflated 49%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/sql/data_deduplicate.csv (deflated 12%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/sql/data_union_exclude_expected.csv (deflated 12%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/sql/data_safe_subtract.csv (deflated 18%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/sql/data_safe_add.csv (deflated 20%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/sql/data_width_bucket.csv (deflated 67%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/sql/data_star_aggregate.csv (deflated 25%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/sql/data_events_20180102.csv (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/sql/data_unpivot_bool.csv (deflated 23%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/sql/data_union_expected.csv (deflated 18%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/sql/data_events_20180103.csv (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/sql/data_events_20180101.csv (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/sql/data_safe_divide.csv (deflated 17%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/sql/data_union_table_2.csv (deflated 13%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/sql/data_generate_surrogate_key.csv (deflated 47%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/sql/data_union_events_expected.csv (deflated 29%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/sql/data_generate_series.csv (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/sql/data_safe_divide_denominator_expressions.csv (deflated 22%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/sql/data_star.csv (deflated 17%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/sql/data_get_query_results_as_dict.csv (deflated 7%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/.gitkeep (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/datetime/ (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/datetime/data_date_spine.csv (deflated 62%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/geo/ (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/geo/data_haversine_km.csv (deflated 14%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/geo/data_haversine_mi.csv (deflated 14%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/etc/ (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/integration_tests/data/etc/data_people.csv (deflated 49%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/dbt_project.yml (deflated 33%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/Makefile (deflated 38%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/.circleci/ (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/.circleci/config.yml (deflated 80%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/LICENSE (deflated 65%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/pytest.ini (deflated 31%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/.gitignore (deflated 15%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/RELEASE.md (deflated 56%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/CHANGELOG.md (deflated 72%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/run_test.sh (deflated 41%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/.github/ (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/.github/ISSUE_TEMPLATE/ (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/.github/ISSUE_TEMPLATE/dbt_minor_release.md (deflated 53%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/.github/ISSUE_TEMPLATE/feature_request.md (deflated 47%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/.github/ISSUE_TEMPLATE/bug_report.md (deflated 52%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/.github/ISSUE_TEMPLATE/utils_minor_release.md (deflated 69%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/.github/pull_request_template.md (deflated 46%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/.github/workflows/ (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/.github/workflows/create-table-of-contents.yml (deflated 45%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/.github/CODEOWNERS (deflated 19%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/docs/ (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/docs/decisions/ (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/docs/decisions/README.md (deflated 46%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/docs/decisions/adr-0002-cross-database-utils.md (deflated 60%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/docs/decisions/adr-0001-decision-record-format.md (deflated 52%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/docs/decisions/adr-0000-documenting-architecture-decisions.md (deflated 54%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/etc/ (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/etc/dbt-logo.png (deflated 2%)\n",
            "  adding: content/sales_analytics/dbt_packages/dbt_utils/dev-requirements.txt (deflated 66%)\n",
            "  adding: content/sales_analytics/target/ (stored 0%)\n",
            "  adding: content/sales_analytics/target/index.html (deflated 73%)\n",
            "  adding: content/sales_analytics/target/partial_parse.msgpack (deflated 85%)\n",
            "  adding: content/sales_analytics/target/semantic_manifest.json (deflated 45%)\n",
            "  adding: content/sales_analytics/target/graph.gpickle (deflated 77%)\n",
            "  adding: content/sales_analytics/target/compiled/ (stored 0%)\n",
            "  adding: content/sales_analytics/target/compiled/sales_analytics/ (stored 0%)\n",
            "  adding: content/sales_analytics/target/compiled/sales_analytics/models/ (stored 0%)\n",
            "  adding: content/sales_analytics/target/compiled/sales_analytics/models/schema.yml/ (stored 0%)\n",
            "  adding: content/sales_analytics/target/compiled/sales_analytics/models/schema.yml/dbt_utils_expression_is_true_s_1128924b3db40e81d5f55a18a3c89e04.sql (deflated 9%)\n",
            "  adding: content/sales_analytics/target/compiled/sales_analytics/models/schema.yml/dbt_utils_expression_is_true_s_6f39fe063d3bb39ea6b025c38f6fac44.sql (deflated 10%)\n",
            "  adding: content/sales_analytics/target/compiled/sales_analytics/models/schema.yml/dbt_utils_expression_is_true_s_6652992a83cefec692783bb106eab889.sql (deflated 5%)\n",
            "  adding: content/sales_analytics/target/compiled/sales_analytics/models/schema.yml/not_null_silver_fact_sales_sale_id.sql (deflated 20%)\n",
            "  adding: content/sales_analytics/target/compiled/sales_analytics/models/schema.yml/unique_silver_fact_sales_sale_id.sql (deflated 30%)\n",
            "  adding: content/sales_analytics/target/compiled/sales_analytics/models/gold/ (stored 0%)\n",
            "  adding: content/sales_analytics/target/compiled/sales_analytics/models/gold/gold_fact_sales_aggregated.sql (deflated 57%)\n",
            "  adding: content/sales_analytics/target/compiled/sales_analytics/models/gold/gold_monthly_revenue_yoy.sql (deflated 54%)\n",
            "  adding: content/sales_analytics/target/compiled/sales_analytics/models/silver/ (stored 0%)\n",
            "  adding: content/sales_analytics/target/compiled/sales_analytics/models/silver/silver_fact_sales.sql (deflated 54%)\n",
            "  adding: content/sales_analytics/target/compiled/sales_analytics/models/silver/silver_dim_customer.sql (stored 0%)\n",
            "  adding: content/sales_analytics/target/compiled/sales_analytics/models/silver/silver_dim_location.sql (stored 0%)\n",
            "  adding: content/sales_analytics/target/compiled/sales_analytics/models/silver/silver_dim_time.sql (stored 0%)\n",
            "  adding: content/sales_analytics/target/compiled/sales_analytics/models/silver/silver_dim_product.sql (stored 0%)\n",
            "  adding: content/sales_analytics/target/catalog.json (deflated 90%)\n",
            "  adding: content/sales_analytics/target/manifest.json (deflated 88%)\n",
            "  adding: content/sales_analytics/target/graph_summary.json (deflated 75%)\n",
            "  adding: content/sales_analytics/target/run_results.json (deflated 78%)\n",
            "  adding: content/sales_analytics/target/run/ (stored 0%)\n",
            "  adding: content/sales_analytics/target/run/sales_analytics/ (stored 0%)\n",
            "  adding: content/sales_analytics/target/run/sales_analytics/models/ (stored 0%)\n",
            "  adding: content/sales_analytics/target/run/sales_analytics/models/schema.yml/ (stored 0%)\n",
            "  adding: content/sales_analytics/target/run/sales_analytics/models/schema.yml/dbt_utils_expression_is_true_s_1128924b3db40e81d5f55a18a3c89e04.sql (deflated 43%)\n",
            "  adding: content/sales_analytics/target/run/sales_analytics/models/schema.yml/dbt_utils_expression_is_true_s_6f39fe063d3bb39ea6b025c38f6fac44.sql (deflated 44%)\n",
            "  adding: content/sales_analytics/target/run/sales_analytics/models/schema.yml/dbt_utils_expression_is_true_s_6652992a83cefec692783bb106eab889.sql (deflated 42%)\n",
            "  adding: content/sales_analytics/target/run/sales_analytics/models/schema.yml/not_null_silver_fact_sales_sale_id.sql (deflated 47%)\n",
            "  adding: content/sales_analytics/target/run/sales_analytics/models/schema.yml/unique_silver_fact_sales_sale_id.sql (deflated 48%)\n",
            "  adding: content/sales_analytics/target/run/sales_analytics/models/gold/ (stored 0%)\n",
            "  adding: content/sales_analytics/target/run/sales_analytics/models/gold/gold_fact_sales_aggregated.sql (deflated 57%)\n",
            "  adding: content/sales_analytics/target/run/sales_analytics/models/gold/gold_monthly_revenue_yoy.sql (deflated 54%)\n",
            "  adding: content/sales_analytics/target/run/sales_analytics/models/silver/ (stored 0%)\n",
            "  adding: content/sales_analytics/target/run/sales_analytics/models/silver/silver_fact_sales.sql (deflated 54%)\n",
            "  adding: content/sales_analytics/target/run/sales_analytics/models/silver/silver_dim_customer.sql (deflated 30%)\n",
            "  adding: content/sales_analytics/target/run/sales_analytics/models/silver/silver_dim_location.sql (deflated 29%)\n",
            "  adding: content/sales_analytics/target/run/sales_analytics/models/silver/silver_dim_time.sql (deflated 28%)\n",
            "  adding: content/sales_analytics/target/run/sales_analytics/models/silver/silver_dim_product.sql (deflated 29%)\n",
            "  adding: content/sales_analytics/package-lock.yml (deflated 21%)\n",
            "  adding: content/sales_analytics/models/ (stored 0%)\n",
            "  adding: content/sales_analytics/models/schema.yml (deflated 64%)\n",
            "  adding: content/sales_analytics/models/sources/ (stored 0%)\n",
            "  adding: content/sales_analytics/models/sources/sources.yml (deflated 47%)\n",
            "  adding: content/sales_analytics/models/gold/ (stored 0%)\n",
            "  adding: content/sales_analytics/models/gold/gold_fact_sales_aggregated.sql (deflated 54%)\n",
            "  adding: content/sales_analytics/models/gold/gold_monthly_revenue_yoy.sql (deflated 52%)\n",
            "  adding: content/sales_analytics/models/silver/ (stored 0%)\n",
            "  adding: content/sales_analytics/models/silver/silver_fact_sales.sql (deflated 51%)\n",
            "  adding: content/sales_analytics/models/silver/silver_dim_customer.sql (deflated 3%)\n",
            "  adding: content/sales_analytics/models/silver/silver_dim_location.sql (deflated 3%)\n",
            "  adding: content/sales_analytics/models/silver/silver_dim_time.sql (deflated 5%)\n",
            "  adding: content/sales_analytics/models/silver/silver_dim_product.sql (deflated 3%)\n",
            "  adding: content/sales_analytics/dbt_docs.zip (stored 0%)\n",
            "  adding: content/sales_analytics/dbt_project.yml (deflated 49%)\n",
            "  adding: content/sales_analytics/sales.duckdb (deflated 81%)\n",
            "  adding: content/sales_analytics/gx_data_docs.zip (stored 0%)\n",
            "  adding: content/sales_analytics/golden_export.zip (stored 0%)\n",
            "  adding: content/sales_analytics/logs/ (stored 0%)\n",
            "  adding: content/sales_analytics/logs/dbt.log (deflated 86%)\n",
            "  adding: content/sales_analytics/profiles.yml (deflated 34%)\n",
            "  adding: content/sales_analytics/packages.yml (deflated 11%)\n",
            "  adding: content/sales_analytics/.user.yml (stored 0%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2fd33883-086f-411b-89a0-a5d5587fc457\", \"sales_analytics_complete.zip\", 2607992)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Descargando sales_analytics_complete.zip...\n",
            "Contenido incluido:\n",
            "/content/sales_analytics:\n",
            "dbt_docs.zip\n",
            "dbt_packages\n",
            "dbt_project.yml\n",
            "golden_export.zip\n",
            "gx_data_docs.zip\n",
            "logs\n",
            "models\n",
            "package-lock.yml\n",
            "packages.yml\n",
            "profiles.yml\n",
            "sales_analytics_complete.zip\n",
            "sales.duckdb\n",
            "target\n",
            "\n",
            "/content/sales_analytics/dbt_packages:\n",
            "dbt_utils\n",
            "\n",
            "/content/sales_analytics/dbt_packages/dbt_utils:\n",
            "CHANGELOG.md\n",
            "CONTRIBUTING.md\n",
            "dbt_project.yml\n",
            "dev-requirements.txt\n",
            "docker-compose.yml\n",
            "docs\n",
            "etc\n",
            "integration_tests\n",
            "LICENSE\n",
            "macros\n",
            "Makefile\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Key Takeaways for Modern Data Platforms**\n",
        "- Scalable ELT with dbt + Medallion/Kimball\n",
        "- Built-in governance via dbt tests + Great Expectations\n",
        "- Export-ready gold layers for BI/ML\n",
        "- CI/CD ready (GitHub Actions workflow included)"
      ],
      "metadata": {
        "id": "cibz_7vWHDwL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **HAVE FUN CREATINGğŸ¤—**\n",
        "\n",
        "*If this project has helpful to you, stop by my Linkedin ad let me know how it helped! â˜•*\n",
        "\n",
        "* **linkedIn:** https://www.linkedin.com/in/cristhianandrescalleseverino/\n",
        "\n",
        "I've left the following cells open for you to add your personalized queries. Go ahead and **Create**.\n",
        "\n",
        "***Being 1% better every day is the key ğŸ”¥***"
      ],
      "metadata": {
        "id": "WpsJ5MpxHGb6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T__n4_znHMkR"
      },
      "execution_count": 62,
      "outputs": []
    }
  ]
}